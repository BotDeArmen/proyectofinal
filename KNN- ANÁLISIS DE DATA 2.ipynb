{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyOVE0IGnN1mdOUURNpVzway"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import plotly.express as px\n","import matplotlib.pyplot as plt"],"metadata":{"id":"jZcXyYpOnDMi","executionInfo":{"status":"ok","timestamp":1745745147814,"user_tz":-120,"elapsed":1611,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["df2=pd.read_csv('avocado.csv')\n","# --- PASO PREVIO: Asegurarse que 'df2' existe y está preparado ---\n","# Asumimos que df2 es el DataFrame original cargado previamente.\n","if 'df2' not in locals() or not isinstance(df2, pd.DataFrame):\n","    print(\"Error: El DataFrame 'df2' no parece estar cargado o no es un DataFrame.\")\n","    exit()\n","else:\n","    print(\"Usando el DataFrame 'df2' existente.\")\n","    # Verificar que la columna 'region' existe\n","    if 'region' not in df2.columns:\n","        print(\"Error: La columna 'region' no se encontró en df2.\")\n","        exit()\n","\n","# --- 1. Definir el Mapeo de Subregión a Región Principal ---\n","\n","# !! IMPORTANTE !! Revisa y ajusta este diccionario según tu conocimiento\n","# o los criterios específicos que quieras usar para la jerarquía.\n","# He agrupado NNE bajo Northeast como sugeriste.\n","# Las 9 regiones principales se mapean a sí mismas.\n","# TotalUS se mapea a sí mismo.\n","\n","region_mapping = {\n","    # Northeast (Incluyendo NorthernNewEngland)\n","    'Albany': 'Northeast', 'BaltimoreWashington': 'Northeast', 'Boston': 'Northeast',\n","    'BuffaloRochester': 'Northeast', 'HarrisburgScranton': 'Northeast',\n","    'HartfordSpringfield': 'Northeast', 'NewYork': 'Northeast', 'Philadelphia': 'Northeast',\n","    'Syracuse': 'Northeast', 'NorthernNewEngland': 'Northeast', # NNE agrupado en NE\n","    'Northeast': 'Northeast', # Región principal se mapea a sí misma\n","\n","    # Southeast\n","    'Atlanta': 'Southeast', 'Charlotte': 'Southeast', 'Jacksonville': 'Southeast',\n","    'MiamiFtLauderdale': 'Southeast', 'Orlando': 'Southeast', 'RaleighGreensboro': 'Southeast',\n","    'RichmondNorfolk': 'Southeast', 'Roanoke': 'Southeast', 'SouthCarolina': 'Southeast',\n","    'Tampa': 'Southeast', 'Nashville': 'Southeast', # Nashville más común en SE\n","    'Southeast': 'Southeast', # Región principal\n","\n","    # GreatLakes (Incluye algunas ciudades que a veces se ponen en Midsouth)\n","    'Chicago': 'GreatLakes', 'CincinnatiDayton': 'GreatLakes', 'Columbus': 'GreatLakes',\n","    'Detroit': 'GreatLakes', 'GrandRapids': 'GreatLakes', 'Indianapolis': 'GreatLakes',\n","    'Pittsburgh': 'GreatLakes',\n","    'GreatLakes': 'GreatLakes', # Región principal\n","\n","    # Midsouth (Según tu lista de principales)\n","    'Louisville': 'Midsouth', 'StLouis': 'Midsouth', # StLouis aquí\n","    'Midsouth': 'Midsouth', # Región principal\n","\n","    # SouthCentral\n","    'DallasFtWorth': 'SouthCentral', 'Houston': 'SouthCentral', 'NewOrleansMobile': 'SouthCentral',\n","    'SouthCentral': 'SouthCentral', # Región principal\n","\n","    # WestTexNewMexico\n","    'WestTexNewMexico': 'WestTexNewMexico', # Región principal\n","\n","    # Plains\n","    'Boise': 'Plains', 'Denver': 'Plains', # Boise asignado aquí\n","    'Plains': 'Plains', # Región principal\n","\n","    # West\n","    'California': 'West', 'LasVegas': 'West', 'LosAngeles': 'West', 'PhoenixTucson': 'West',\n","    'Portland': 'West', 'Sacramento': 'West', 'SanDiego': 'West', 'SanFrancisco': 'West',\n","    'Seattle': 'West', 'Spokane': 'West',\n","    'West': 'West', # Región principal\n","\n","    # Caso Especial\n","    'TotalUS': 'TotalUS'\n","}\n","\n","print(\"\\nMapeo de Regiones Definido.\")\n","# Puedes imprimir el diccionario 'region_mapping' si quieres verlo completo\n","\n","# --- 2. Crear la Nueva Columna \"Clasificación\" ---\n","\n","# Usamos el método .map() en la columna 'region' de df2.\n","# .map() buscará cada valor de 'region' en las claves del diccionario 'region_mapping'\n","# y devolverá el valor asociado (la región principal).\n","# Si una región de df2 no está en el diccionario, .map() devolverá NaN.\n","df2['Clasificación'] = df2['region'].map(region_mapping)\n","\n","print(\"Nueva columna 'Clasificación' creada.\")\n","\n","# --- 3. Verificar Resultados ---\n","\n","# Contar cuántas filas corresponden a cada Región Principal (Clasificación)\n","print(\"\\nConteo de filas por nueva 'Clasificación':\")\n","print(df2['Clasificación'].value_counts(dropna=False)) # dropna=False muestra si hay NaNs (regiones no mapeadas)\n","\n","# Verificar si hubo regiones que no se pudieron mapear (resultando en NaN)\n","unmapped_regions = df2[df2['Clasificación'].isnull()]['region'].unique()\n","if len(unmapped_regions) > 0:\n","    print(f\"\\n¡Advertencia! Las siguientes regiones en df2 no se encontraron en el mapeo y tienen 'Clasificación' = NaN:\")\n","    print(unmapped_regions)\n","    print(\"Deberías añadirlas al diccionario 'region_mapping' si quieres clasificarlas.\")\n","else:\n","    print(\"\\nTodas las regiones fueron mapeadas exitosamente.\")\n","\n","# Mostrar las primeras filas con la nueva columna\n","print(\"\\nPrimeras 5 filas de df2 con la nueva columna 'Clasificación':\")\n","print(df2[['region', 'Clasificación']].head())\n","\n","# Mostrar un ejemplo de una subregión y su clasificación\n","print(\"\\nEjemplo de clasificación para 'LosAngeles':\")\n","print(df2[df2['region'] == 'LosAngeles'][['region', 'Clasificación']].head(1))\n","print(\"\\nEjemplo de clasificación para 'West' (región principal):\")\n","print(df2[df2['region'] == 'West'][['region', 'Clasificación']].head(1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iU-OLhgZq7XN","executionInfo":{"status":"ok","timestamp":1745745147837,"user_tz":-120,"elapsed":9,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}},"outputId":"121a32d4-282f-40b7-bb10-94f704414587"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Usando el DataFrame 'df2' existente.\n","\n","Mapeo de Regiones Definido.\n","Nueva columna 'Clasificación' creada.\n","\n","Conteo de filas por nueva 'Clasificación':\n","Clasificación\n","Southeast           4056\n","Northeast           3718\n","West                3718\n","GreatLakes          2704\n","SouthCentral        1352\n","Plains              1014\n","Midsouth            1014\n","TotalUS              338\n","WestTexNewMexico     335\n","Name: count, dtype: int64\n","\n","Todas las regiones fueron mapeadas exitosamente.\n","\n","Primeras 5 filas de df2 con la nueva columna 'Clasificación':\n","   region Clasificación\n","0  Albany     Northeast\n","1  Albany     Northeast\n","2  Albany     Northeast\n","3  Albany     Northeast\n","4  Albany     Northeast\n","\n","Ejemplo de clasificación para 'LosAngeles':\n","          region Clasificación\n","1144  LosAngeles          West\n","\n","Ejemplo de clasificación para 'West' (región principal):\n","     region Clasificación\n","2704   West          West\n"]}]},{"cell_type":"markdown","source":["## KNN"],"metadata":{"id":"Nm7dkRijjlaa"}},{"cell_type":"code","source":["\n","# Importar bibliotecas necesarias\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import gc\n","\n","# Modelos, preprocesamiento y métricas de Scikit-learn\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# --- Configuración ---\n","TEST_SIZE = 0.20\n","RANDOM_STATE = 42\n","MIN_SAMPLES_FOR_EVAL = 10  # Mínimo de muestras NO CERO para intentar evaluación\n","MIN_SAMPLES_FOR_TRAIN = 5  # Mínimo de muestras NO CERO para entrenar modelo final (debe ser >= K)\n","N_NEIGHBORS_KNN = 5\n","R2_THRESHOLD = 0.69      # Umbral R² para decidir si imputar\n","PROPORTION_ZEROS_THRESHOLD = 0.50 # Umbral máximo de ceros permitido\n","\n","COLUMNA_TARGET = 'Large Bags'\n","COLUMNA_PREDICCION = 'KNN_Prediction' # Columna donde guardar predicciones\n","\n","# --- Preparación de df2 (Asegúrate que esta sección esté completa y funcione) ---\n","# [COPIAR AQUÍ LA SECCIÓN DE PREPARACIÓN DE df2 DEL SCRIPT ANTERIOR]\n","# --- Inicio de sección copiada ---\n","if 'df2' not in locals() or not isinstance(df2, pd.DataFrame):\n","    print(\"Error: El DataFrame 'df2' no está definido. Cárgalo primero.\"); exit()\n","else:\n","    print(\"Usando el DataFrame 'df2' existente.\")\n","\n","print(\"\\nPreparando datos en df2 (índice, tipos numéricos, features de tiempo)...\")\n","try:\n","    # Asegurar índice Date\n","    if not isinstance(df2.index, pd.DatetimeIndex):\n","        if 'Date' in df2.columns:\n","             df2['Date'] = pd.to_datetime(df2['Date'])\n","             df2.set_index('Date', inplace=True)\n","             df2.sort_index(inplace=True)\n","        elif not isinstance(df2.index, pd.DatetimeIndex):\n","             df2.index = pd.to_datetime(df2.index)\n","             df2.sort_index(inplace=True)\n","        else:\n","             df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime preparado y ordenado.\")\n","    elif not df2.index.is_monotonic_increasing:\n","        df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime ordenado.\")\n","\n","    # Crear Features de Tiempo para KNN\n","    features = ['Fecha_Ordinal', 'Mes', 'SemanaDelAno'] # Definir features aquí\n","    if 'Fecha_Ordinal' not in df2.columns:\n","        df2['Fecha_Ordinal'] = df2.index.map(datetime.date.toordinal)\n","        print(\"  - Creada columna 'Fecha_Ordinal'.\")\n","    if 'Mes' not in df2.columns:\n","        df2['Mes'] = df2.index.month\n","        print(\"  - Creada columna 'Mes'.\")\n","    if 'SemanaDelAno' not in df2.columns:\n","        df2['SemanaDelAno'] = df2.index.isocalendar().week.astype(np.int32)\n","        print(\"  - Creada columna 'SemanaDelAno'.\")\n","except Exception as e:\n","    print(f\"Error durante la preparación de datos: {e}\"); exit()\n","\n","cols_to_check = ['Large Bags', 'Total Bags', 'Total Volume', 'AveragePrice']\n","print(f\"Asegurando que {cols_to_check} sean numéricas y rellenando NaNs con 0...\")\n","for col in cols_to_check:\n","    if col in df2.columns:\n","         if not pd.api.types.is_numeric_dtype(df2[col]):\n","              print(f\"  - Convirtiendo '{col}' a numérico...\")\n","              df2[col] = pd.to_numeric(df2[col], errors='coerce')\n","         if df2[col].isnull().any():\n","              print(f\"  - Rellenando NaNs en '{col}' con 0...\")\n","              df2[col] = df2[col].fillna(0)\n","\n","print(\"Optimizando tipos de datos...\")\n","try:\n","    if 'region' in df2.columns: df2['region'] = df2['region'].astype('category')\n","    if 'type' in df2.columns: df2['type'] = df2['type'].astype('category')\n","    for col in df2.select_dtypes(include=['float64']).columns:\n","        # Evitar convertir KNN_Prediction si ya existe y tiene NaNs\n","        if col != COLUMNA_PREDICCION or not (COLUMNA_PREDICCION in df2 and df2[col].isnull().any()):\n","            df2[col] = df2[col].astype(np.float32)\n","    for col in df2.select_dtypes(include=['int64']).columns:\n","        if df2[col].min() >= np.iinfo(np.int32).min and df2[col].max() <= np.iinfo(np.int32).max:\n","             df2[col] = df2[col].astype(np.int32)\n","    print(\"Optimización de tipos completada.\")\n","except Exception as e_opt: print(f\"Advertencia durante optimización de tipos: {e_opt}\")\n","# --- Fin de sección copiada ---\n","\n","# --- Evaluación y posterior Imputación Condicional con KNN ---\n","print(f\"\\n--- Iniciando Evaluación e Imputación Condicional (si R² > {R2_THRESHOLD}) para '{COLUMNA_TARGET}' ---\")\n","\n","# Inicializar columna para guardar predicciones (solo para los ceros imputados)\n","df2[COLUMNA_PREDICCION] = np.nan\n","\n","# Lista para almacenar resultados de evaluación\n","evaluation_results = []\n","imputed_points_total = 0\n","\n","# Asegurar columnas antes del bucle\n","required_loop_cols = ['type', 'region', COLUMNA_TARGET] + features\n","if not all(col in df2.columns for col in required_loop_cols):\n","      print(f\"Error: Faltan columnas necesarias ({required_loop_cols}) en df2.\"); exit()\n","\n","# --- Bucle Principal por Grupo ---\n","total_grupos = len(df2.groupby(['type', 'region']))\n","grupo_actual = 0\n","\n","for (tipo, region), group_df in df2.groupby(['type', 'region']):\n","    grupo_actual += 1\n","    print(f\"\\nProcesando Grupo {grupo_actual}/{total_grupos}: {tipo}/{region}...\")\n","\n","    # Variables para limpieza en finally\n","    # Evaluación\n","    knn_eval = None; scaler_eval = None; y_pred_eval = None; X_eval = None; y_eval = None;\n","    X_train_eval = None; X_test_eval = None; y_train_eval = None; y_test_eval = None;\n","    X_train_scaled_eval = None; X_test_scaled_eval = None; non_zero_data = None;\n","    # Imputación\n","    knn_impute = None; scaler_impute = None; X_all_train = None; y_all_train = None;\n","    X_impute_features = None; X_all_train_scaled = None; X_impute_scaled = None;\n","    imputed_values = None; zero_data = None\n","\n","    r2_eval = np.nan # Inicializar R² de evaluación como NaN\n","\n","    try:\n","        # 1. Separar datos cero y no cero\n","        non_zero_data = group_df[group_df[COLUMNA_TARGET] > 0].copy()\n","        zero_data = group_df[group_df[COLUMNA_TARGET] == 0].copy()\n","        n_non_zero = len(non_zero_data)\n","        n_zero = len(zero_data)\n","        n_total = len(group_df)\n","\n","        print(f\"  - Total: {n_total}, No Cero: {n_non_zero}, Cero: {n_zero}\")\n","\n","        # 2. Chequeos iniciales (antes de evaluar o imputar)\n","        if n_zero == 0:\n","            print(\"  - OK: No hay ceros que imputar en este grupo.\")\n","            continue # Pasar al siguiente grupo\n","\n","        proportion_zeros = n_zero / n_total if n_total > 0 else 0\n","        if proportion_zeros >= PROPORTION_ZEROS_THRESHOLD:\n","            print(f\"  - OMITIDO IMPUTACIÓN: Proporción de ceros >= {PROPORTION_ZEROS_THRESHOLD*100:.0f}% ({proportion_zeros*100:.1f}%).\")\n","            continue\n","\n","        if n_non_zero < MIN_SAMPLES_FOR_TRAIN: # Mínimo absoluto para entrenar algo\n","             print(f\"  - OMITIDO IMPUTACIÓN: Insuficientes muestras no cero ({n_non_zero} < {MIN_SAMPLES_FOR_TRAIN}) para entrenar.\")\n","             continue\n","\n","        # --- 3. Fase de Evaluación (si hay suficientes datos) ---\n","        print(\"  - Fase de Evaluación:\")\n","        if n_non_zero < MIN_SAMPLES_FOR_EVAL:\n","            print(f\"    - OMITIDA: Insuficientes muestras no cero ({n_non_zero} < {MIN_SAMPLES_FOR_EVAL}) para una evaluación fiable.\")\n","            r2_eval = np.nan # Marcar que no se pudo evaluar\n","        else:\n","            # Preparar X e y para evaluación\n","            X_eval = non_zero_data[features]\n","            y_eval = non_zero_data[COLUMNA_TARGET]\n","\n","            # Dividir\n","            X_train_eval, X_test_eval, y_train_eval, y_test_eval = train_test_split(\n","                X_eval, y_eval, test_size=TEST_SIZE, random_state=RANDOM_STATE\n","            )\n","            print(f\"    - Split Evaluación: {len(X_train_eval)} train / {len(X_test_eval)} test\")\n","\n","            # Escalar (basado en train_eval)\n","            scaler_eval = StandardScaler()\n","            X_train_scaled_eval = scaler_eval.fit_transform(X_train_eval)\n","            X_test_scaled_eval = scaler_eval.transform(X_test_eval)\n","\n","            # Entrenar modelo de evaluación\n","            knn_eval = KNeighborsRegressor(n_neighbors=N_NEIGHBORS_KNN, weights='distance')\n","            knn_eval.fit(X_train_scaled_eval, y_train_eval)\n","\n","            # Predecir y Evaluar en test_eval\n","            y_pred_eval = knn_eval.predict(X_test_scaled_eval)\n","            y_pred_eval = np.maximum(0, y_pred_eval) # Ajustar negativos\n","\n","            mae_eval = mean_absolute_error(y_test_eval, y_pred_eval)\n","            rmse_eval = np.sqrt(mean_squared_error(y_test_eval, y_pred_eval))\n","            r2_eval = knn_eval.score(X_test_scaled_eval, y_test_eval) # R²\n","\n","            print(f\"    - Resultados Evaluación (Test Set): MAE={mae_eval:,.2f}, RMSE={rmse_eval:,.2f}, R²={r2_eval:.4f}\")\n","\n","            # Guardar resultados de evaluación\n","            evaluation_results.append({\n","                'type': tipo, 'region': region, 'n_non_zero': n_non_zero, 'n_train_eval': len(X_train_eval),\n","                'n_test_eval': len(X_test_eval), 'MAE_eval': mae_eval, 'RMSE_eval': rmse_eval, 'R2_eval': r2_eval\n","            })\n","\n","        # --- 4. Fase de Imputación Condicional (si R² > umbral) ---\n","        print(\"  - Fase de Imputación:\")\n","        # Proceder solo si la evaluación fue posible Y el R² supera el umbral\n","        if not np.isnan(r2_eval) and r2_eval > R2_THRESHOLD:\n","            print(f\"    - PROCEDIENDO: R² ({r2_eval:.4f}) > umbral ({R2_THRESHOLD}).\")\n","            print(f\"    - Re-entrenando KNN con TODOS los {n_non_zero} datos no cero...\")\n","\n","            # Preparar datos para el modelo FINAL de imputación\n","            X_all_train = non_zero_data[features]\n","            y_all_train = non_zero_data[COLUMNA_TARGET]\n","            X_impute_features = zero_data[features] # Features de los datos a imputar\n","\n","            # Escalar: Ajustar con TODOS los datos no cero\n","            scaler_impute = StandardScaler()\n","            X_all_train_scaled = scaler_impute.fit_transform(X_all_train)\n","            # Aplicar mismo escalador a los datos a imputar\n","            X_impute_scaled = scaler_impute.transform(X_impute_features)\n","\n","            # Entrenar modelo FINAL de imputación\n","            knn_impute = KNeighborsRegressor(n_neighbors=N_NEIGHBORS_KNN, weights='distance')\n","            knn_impute.fit(X_all_train_scaled, y_all_train)\n","\n","            # Predecir los valores para los ceros\n","            imputed_values = knn_impute.predict(X_impute_scaled)\n","            imputed_values = np.maximum(0, imputed_values) # Ajustar negativos\n","\n","            # Guardar las predicciones en la columna COLUMNA_PREDICCION\n","            indices_imputar = zero_data.index\n","            df2.loc[indices_imputar, COLUMNA_PREDICCION] = imputed_values\n","            imputed_points_total += len(indices_imputar)\n","            print(f\"    - ¡ÉXITO! Se guardaron {len(indices_imputar)} predicciones en '{COLUMNA_PREDICCION}'.\")\n","\n","        elif np.isnan(r2_eval):\n","             print(f\"    - OMITIDA: No se pudo realizar la evaluación previa (pocos datos).\")\n","        else:\n","             print(f\"    - OMITIDA: R² ({r2_eval:.4f}) no supera el umbral ({R2_THRESHOLD}).\")\n","\n","\n","    except Exception as e:\n","        print(f\"  - ERROR Inesperado ({type(e).__name__}: {str(e)[:100]}...).\")\n","\n","    finally:\n","         # Limpieza de Memoria\n","         variables_a_borrar = [\n","             'group_df', 'non_zero_data', 'zero_data',\n","             'knn_eval', 'scaler_eval', 'y_pred_eval', 'X_eval', 'y_eval', 'X_train_eval',\n","             'X_test_eval', 'y_train_eval', 'y_test_eval', 'X_train_scaled_eval', 'X_test_scaled_eval',\n","             'knn_impute', 'scaler_impute', 'X_all_train', 'y_all_train', 'X_impute_features',\n","             'X_all_train_scaled', 'X_impute_scaled', 'imputed_values'\n","             ]\n","         for var_name in variables_a_borrar:\n","              try:\n","                  if var_name in locals(): del locals()[var_name]\n","              except NameError: pass\n","         # gc.collect()\n","\n","print(f\"\\n--- Proceso de Evaluación e Imputación Condicional Finalizado ---\")\n","print(f\"Se guardaron predicciones en '{COLUMNA_PREDICCION}' para un total de {imputed_points_total} puntos (ceros originales).\")\n","print(f\"Para los demás ceros, o grupos omitidos, '{COLUMNA_PREDICCION}' contendrá NaN.\")\n","\n","# --- Opcional: Mostrar Resultados Consolidados de la Evaluación ---\n","if evaluation_results:\n","    results_eval_df = pd.DataFrame(evaluation_results)\n","    print(\"\\nResumen de Resultados de la Fase de Evaluación (Solo grupos evaluados):\")\n","    pd.set_option('display.max_rows', None); pd.set_option('display.max_columns', None); pd.set_option('display.width', 120)\n","    print(results_eval_df.sort_values(by='R2_eval', ascending=False).round({'MAE_eval': 2, 'RMSE_eval': 2, 'R2_eval': 4}))\n","    pd.reset_option('display.max_rows'); pd.reset_option('display.max_columns'); pd.reset_option('display.width')\n","else:\n","    print(\"\\nNo se generaron resultados de evaluación (quizás por falta de datos suficientes en los grupos).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iJGkj1ONA-j_","executionInfo":{"status":"ok","timestamp":1745745151325,"user_tz":-120,"elapsed":3477,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}},"outputId":"4933451f-bbf0-4d74-f234-73d4a0a362a5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Usando el DataFrame 'df2' existente.\n","\n","Preparando datos en df2 (índice, tipos numéricos, features de tiempo)...\n","  - Índice Datetime preparado y ordenado.\n","  - Creada columna 'Fecha_Ordinal'.\n","  - Creada columna 'Mes'.\n","  - Creada columna 'SemanaDelAno'.\n","Asegurando que ['Large Bags', 'Total Bags', 'Total Volume', 'AveragePrice'] sean numéricas y rellenando NaNs con 0...\n","Optimizando tipos de datos...\n","Optimización de tipos completada.\n","\n","--- Iniciando Evaluación e Imputación Condicional (si R² > 0.69) para 'Large Bags' ---\n","\n","Procesando Grupo 1/108: conventional/Albany...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 2/108: conventional/Atlanta...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 3/108: conventional/BaltimoreWashington...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 4/108: conventional/Boise...\n","  - Total: 169, No Cero: 142, Cero: 27\n","  - Fase de Evaluación:\n","    - Split Evaluación: 113 train / 29 test\n","    - Resultados Evaluación (Test Set): MAE=2,048.73, RMSE=4,168.67, R²=0.4906\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4906) no supera el umbral (0.69).\n","\n","Procesando Grupo 5/108: conventional/Boston...\n","  - Total: 169, No Cero: 162, Cero: 7\n","  - Fase de Evaluación:\n","    - Split Evaluación: 129 train / 33 test\n","    - Resultados Evaluación (Test Set): MAE=3,872.46, RMSE=7,893.32, R²=0.6002\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6002) no supera el umbral (0.69).\n","\n","Procesando Grupo 6/108: conventional/BuffaloRochester...\n","  - Total: 169, No Cero: 115, Cero: 54\n","  - Fase de Evaluación:\n","    - Split Evaluación: 92 train / 23 test\n","    - Resultados Evaluación (Test Set): MAE=2,689.22, RMSE=6,004.04, R²=0.8787\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.8787) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 115 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 7/108: conventional/California...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 8/108: conventional/Charlotte...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 9/108: conventional/Chicago...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 10/108: conventional/CincinnatiDayton...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 11/108: conventional/Columbus...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 12/108: conventional/DallasFtWorth...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 13/108: conventional/Denver...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 14/108: conventional/Detroit...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 15/108: conventional/GrandRapids...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 16/108: conventional/GreatLakes...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 17/108: conventional/HarrisburgScranton...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 18/108: conventional/HartfordSpringfield...\n","  - Total: 169, No Cero: 168, Cero: 1\n","  - Fase de Evaluación:\n","    - Split Evaluación: 134 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=1,837.34, RMSE=3,696.25, R²=-1.5861\n","  - Fase de Imputación:\n","    - OMITIDA: R² (-1.5861) no supera el umbral (0.69).\n","\n","Procesando Grupo 19/108: conventional/Houston...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 20/108: conventional/Indianapolis...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 21/108: conventional/Jacksonville...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 22/108: conventional/LasVegas...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 23/108: conventional/LosAngeles...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 24/108: conventional/Louisville...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 25/108: conventional/MiamiFtLauderdale...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 26/108: conventional/Midsouth...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 27/108: conventional/Nashville...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 28/108: conventional/NewOrleansMobile...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 29/108: conventional/NewYork...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 30/108: conventional/Northeast...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 31/108: conventional/NorthernNewEngland...\n","  - Total: 169, No Cero: 122, Cero: 47\n","  - Fase de Evaluación:\n","    - Split Evaluación: 97 train / 25 test\n","    - Resultados Evaluación (Test Set): MAE=5,665.93, RMSE=10,962.41, R²=0.6757\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6757) no supera el umbral (0.69).\n","\n","Procesando Grupo 32/108: conventional/Orlando...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 33/108: conventional/Philadelphia...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 34/108: conventional/PhoenixTucson...\n","  - Total: 169, No Cero: 158, Cero: 11\n","  - Fase de Evaluación:\n","    - Split Evaluación: 126 train / 32 test\n","    - Resultados Evaluación (Test Set): MAE=29,169.37, RMSE=40,252.16, R²=0.7786\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7786) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 158 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 35/108: conventional/Pittsburgh...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 36/108: conventional/Plains...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 37/108: conventional/Portland...\n","  - Total: 169, No Cero: 167, Cero: 2\n","  - Fase de Evaluación:\n","    - Split Evaluación: 133 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=15,468.17, RMSE=32,754.67, R²=0.3301\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3301) no supera el umbral (0.69).\n","\n","Procesando Grupo 38/108: conventional/RaleighGreensboro...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 39/108: conventional/RichmondNorfolk...\n","  - Total: 169, No Cero: 150, Cero: 19\n","  - Fase de Evaluación:\n","    - Split Evaluación: 120 train / 30 test\n","    - Resultados Evaluación (Test Set): MAE=1,641.26, RMSE=2,712.97, R²=0.5319\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5319) no supera el umbral (0.69).\n","\n","Procesando Grupo 40/108: conventional/Roanoke...\n","  - Total: 169, No Cero: 149, Cero: 20\n","  - Fase de Evaluación:\n","    - Split Evaluación: 119 train / 30 test\n","    - Resultados Evaluación (Test Set): MAE=2,008.02, RMSE=3,735.08, R²=0.6642\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6642) no supera el umbral (0.69).\n","\n","Procesando Grupo 41/108: conventional/Sacramento...\n","  - Total: 169, No Cero: 119, Cero: 50\n","  - Fase de Evaluación:\n","    - Split Evaluación: 95 train / 24 test\n","    - Resultados Evaluación (Test Set): MAE=459.21, RMSE=616.70, R²=0.3634\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3634) no supera el umbral (0.69).\n","\n","Procesando Grupo 42/108: conventional/SanDiego...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 43/108: conventional/SanFrancisco...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 44/108: conventional/Seattle...\n","  - Total: 169, No Cero: 155, Cero: 14\n","  - Fase de Evaluación:\n","    - Split Evaluación: 124 train / 31 test\n","    - Resultados Evaluación (Test Set): MAE=22,065.39, RMSE=46,409.69, R²=0.5696\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5696) no supera el umbral (0.69).\n","\n","Procesando Grupo 45/108: conventional/SouthCarolina...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 46/108: conventional/SouthCentral...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 47/108: conventional/Southeast...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 48/108: conventional/Spokane...\n","  - Total: 169, No Cero: 122, Cero: 47\n","  - Fase de Evaluación:\n","    - Split Evaluación: 97 train / 25 test\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-3-dd99cda5a580>:107: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  total_grupos = len(df2.groupby(['type', 'region']))\n","<ipython-input-3-dd99cda5a580>:110: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  for (tipo, region), group_df in df2.groupby(['type', 'region']):\n"]},{"output_type":"stream","name":"stdout","text":["    - Resultados Evaluación (Test Set): MAE=1,555.34, RMSE=2,749.31, R²=0.7981\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7981) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 122 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 49/108: conventional/StLouis...\n","  - Total: 169, No Cero: 153, Cero: 16\n","  - Fase de Evaluación:\n","    - Split Evaluación: 122 train / 31 test\n","    - Resultados Evaluación (Test Set): MAE=4,565.90, RMSE=6,237.72, R²=0.6260\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6260) no supera el umbral (0.69).\n","\n","Procesando Grupo 50/108: conventional/Syracuse...\n","  - Total: 169, No Cero: 113, Cero: 56\n","  - Fase de Evaluación:\n","    - Split Evaluación: 90 train / 23 test\n","    - Resultados Evaluación (Test Set): MAE=1,363.87, RMSE=2,871.12, R²=0.7855\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7855) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 113 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 51/108: conventional/Tampa...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 52/108: conventional/TotalUS...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 53/108: conventional/West...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 54/108: conventional/WestTexNewMexico...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 55/108: organic/Albany...\n","  - Total: 169, No Cero: 15, Cero: 154\n","  - OMITIDO IMPUTACIÓN: Proporción de ceros >= 50% (91.1%).\n","\n","Procesando Grupo 56/108: organic/Atlanta...\n","  - Total: 169, No Cero: 168, Cero: 1\n","  - Fase de Evaluación:\n","    - Split Evaluación: 134 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=1,829.63, RMSE=3,064.93, R²=0.4983\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4983) no supera el umbral (0.69).\n","\n","Procesando Grupo 57/108: organic/BaltimoreWashington...\n","  - Total: 169, No Cero: 133, Cero: 36\n","  - Fase de Evaluación:\n","    - Split Evaluación: 106 train / 27 test\n","    - Resultados Evaluación (Test Set): MAE=500.69, RMSE=1,188.88, R²=0.7525\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7525) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 133 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 58/108: organic/Boise...\n","  - Total: 169, No Cero: 166, Cero: 3\n","  - Fase de Evaluación:\n","    - Split Evaluación: 132 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=628.95, RMSE=1,093.43, R²=0.3181\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3181) no supera el umbral (0.69).\n","\n","Procesando Grupo 59/108: organic/Boston...\n","  - Total: 169, No Cero: 112, Cero: 57\n","  - Fase de Evaluación:\n","    - Split Evaluación: 89 train / 23 test\n","    - Resultados Evaluación (Test Set): MAE=722.92, RMSE=945.13, R²=0.4378\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4378) no supera el umbral (0.69).\n","\n","Procesando Grupo 60/108: organic/BuffaloRochester...\n","  - Total: 169, No Cero: 118, Cero: 51\n","  - Fase de Evaluación:\n","    - Split Evaluación: 94 train / 24 test\n","    - Resultados Evaluación (Test Set): MAE=1,585.73, RMSE=1,933.59, R²=0.4518\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4518) no supera el umbral (0.69).\n","\n","Procesando Grupo 61/108: organic/California...\n","  - Total: 169, No Cero: 137, Cero: 32\n","  - Fase de Evaluación:\n","    - Split Evaluación: 109 train / 28 test\n","    - Resultados Evaluación (Test Set): MAE=2,707.61, RMSE=4,475.76, R²=-0.1585\n","  - Fase de Imputación:\n","    - OMITIDA: R² (-0.1585) no supera el umbral (0.69).\n","\n","Procesando Grupo 62/108: organic/Charlotte...\n","  - Total: 169, No Cero: 97, Cero: 72\n","  - Fase de Evaluación:\n","    - Split Evaluación: 77 train / 20 test\n","    - Resultados Evaluación (Test Set): MAE=81.61, RMSE=121.95, R²=0.5485\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5485) no supera el umbral (0.69).\n","\n","Procesando Grupo 63/108: organic/Chicago...\n","  - Total: 169, No Cero: 44, Cero: 125\n","  - OMITIDO IMPUTACIÓN: Proporción de ceros >= 50% (74.0%).\n","\n","Procesando Grupo 64/108: organic/CincinnatiDayton...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 65/108: organic/Columbus...\n","  - Total: 169, No Cero: 168, Cero: 1\n","  - Fase de Evaluación:\n","    - Split Evaluación: 134 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=1,601.94, RMSE=2,340.57, R²=0.3939\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3939) no supera el umbral (0.69).\n","\n","Procesando Grupo 66/108: organic/DallasFtWorth...\n","  - Total: 169, No Cero: 128, Cero: 41\n","  - Fase de Evaluación:\n","    - Split Evaluación: 102 train / 26 test\n","    - Resultados Evaluación (Test Set): MAE=503.74, RMSE=815.84, R²=0.6626\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6626) no supera el umbral (0.69).\n","\n","Procesando Grupo 67/108: organic/Denver...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 68/108: organic/Detroit...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 69/108: organic/GrandRapids...\n","  - Total: 169, No Cero: 87, Cero: 82\n","  - Fase de Evaluación:\n","    - Split Evaluación: 69 train / 18 test\n","    - Resultados Evaluación (Test Set): MAE=112.95, RMSE=308.46, R²=-11.6410\n","  - Fase de Imputación:\n","    - OMITIDA: R² (-11.6410) no supera el umbral (0.69).\n","\n","Procesando Grupo 70/108: organic/GreatLakes...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 71/108: organic/HarrisburgScranton...\n","  - Total: 169, No Cero: 93, Cero: 76\n","  - Fase de Evaluación:\n","    - Split Evaluación: 74 train / 19 test\n","    - Resultados Evaluación (Test Set): MAE=351.92, RMSE=597.17, R²=0.8398\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.8398) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 93 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 72/108: organic/HartfordSpringfield...\n","  - Total: 169, No Cero: 89, Cero: 80\n","  - Fase de Evaluación:\n","    - Split Evaluación: 71 train / 18 test\n","    - Resultados Evaluación (Test Set): MAE=92.90, RMSE=115.61, R²=-2.8255\n","  - Fase de Imputación:\n","    - OMITIDA: R² (-2.8255) no supera el umbral (0.69).\n","\n","Procesando Grupo 73/108: organic/Houston...\n","  - Total: 169, No Cero: 103, Cero: 66\n","  - Fase de Evaluación:\n","    - Split Evaluación: 82 train / 21 test\n","    - Resultados Evaluación (Test Set): MAE=876.55, RMSE=1,720.86, R²=0.0935\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.0935) no supera el umbral (0.69).\n","\n","Procesando Grupo 74/108: organic/Indianapolis...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 75/108: organic/Jacksonville...\n","  - Total: 169, No Cero: 88, Cero: 81\n","  - Fase de Evaluación:\n","    - Split Evaluación: 70 train / 18 test\n","    - Resultados Evaluación (Test Set): MAE=737.95, RMSE=941.43, R²=0.4009\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4009) no supera el umbral (0.69).\n","\n","Procesando Grupo 76/108: organic/LasVegas...\n","  - Total: 169, No Cero: 147, Cero: 22\n","  - Fase de Evaluación:\n","    - Split Evaluación: 117 train / 30 test\n","    - Resultados Evaluación (Test Set): MAE=424.51, RMSE=751.55, R²=0.4967\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4967) no supera el umbral (0.69).\n","\n","Procesando Grupo 77/108: organic/LosAngeles...\n","  - Total: 169, No Cero: 134, Cero: 35\n","  - Fase de Evaluación:\n","    - Split Evaluación: 107 train / 27 test\n","    - Resultados Evaluación (Test Set): MAE=2,340.26, RMSE=3,448.73, R²=0.3962\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3962) no supera el umbral (0.69).\n","\n","Procesando Grupo 78/108: organic/Louisville...\n","  - Total: 169, No Cero: 167, Cero: 2\n","  - Fase de Evaluación:\n","    - Split Evaluación: 133 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=657.31, RMSE=1,237.35, R²=0.4406\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4406) no supera el umbral (0.69).\n","\n","Procesando Grupo 79/108: organic/MiamiFtLauderdale...\n","  - Total: 169, No Cero: 107, Cero: 62\n","  - Fase de Evaluación:\n","    - Split Evaluación: 85 train / 22 test\n","    - Resultados Evaluación (Test Set): MAE=200.89, RMSE=340.89, R²=0.7212\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7212) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 107 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 80/108: organic/Midsouth...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 81/108: organic/Nashville...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 82/108: organic/NewOrleansMobile...\n","  - Total: 169, No Cero: 108, Cero: 61\n","  - Fase de Evaluación:\n","    - Split Evaluación: 86 train / 22 test\n","    - Resultados Evaluación (Test Set): MAE=211.47, RMSE=349.48, R²=0.1901\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.1901) no supera el umbral (0.69).\n","\n","Procesando Grupo 83/108: organic/NewYork...\n","  - Total: 169, No Cero: 122, Cero: 47\n","  - Fase de Evaluación:\n","    - Split Evaluación: 97 train / 25 test\n","    - Resultados Evaluación (Test Set): MAE=949.51, RMSE=2,427.92, R²=0.4997\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4997) no supera el umbral (0.69).\n","\n","Procesando Grupo 84/108: organic/Northeast...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 85/108: organic/NorthernNewEngland...\n","  - Total: 169, No Cero: 19, Cero: 150\n","  - OMITIDO IMPUTACIÓN: Proporción de ceros >= 50% (88.8%).\n","\n","Procesando Grupo 86/108: organic/Orlando...\n","  - Total: 169, No Cero: 102, Cero: 67\n","  - Fase de Evaluación:\n","    - Split Evaluación: 81 train / 21 test\n","    - Resultados Evaluación (Test Set): MAE=584.43, RMSE=920.51, R²=0.2590\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.2590) no supera el umbral (0.69).\n","\n","Procesando Grupo 87/108: organic/Philadelphia...\n","  - Total: 169, No Cero: 113, Cero: 56\n","  - Fase de Evaluación:\n","    - Split Evaluación: 90 train / 23 test\n","    - Resultados Evaluación (Test Set): MAE=863.47, RMSE=1,772.24, R²=0.4948\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4948) no supera el umbral (0.69).\n","\n","Procesando Grupo 88/108: organic/PhoenixTucson...\n","  - Total: 169, No Cero: 161, Cero: 8\n","  - Fase de Evaluación:\n","    - Split Evaluación: 128 train / 33 test\n","    - Resultados Evaluación (Test Set): MAE=206.38, RMSE=322.54, R²=0.8491\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.8491) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 161 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 89/108: organic/Pittsburgh...\n","  - Total: 169, No Cero: 140, Cero: 29\n","  - Fase de Evaluación:\n","    - Split Evaluación: 112 train / 28 test\n","    - Resultados Evaluación (Test Set): MAE=102.03, RMSE=159.50, R²=0.5772\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5772) no supera el umbral (0.69).\n","\n","Procesando Grupo 90/108: organic/Plains...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 91/108: organic/Portland...\n","  - Total: 169, No Cero: 168, Cero: 1\n","  - Fase de Evaluación:\n","    - Split Evaluación: 134 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=5,799.13, RMSE=8,900.39, R²=0.2970\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.2970) no supera el umbral (0.69).\n","\n","Procesando Grupo 92/108: organic/RaleighGreensboro...\n","  - Total: 169, No Cero: 166, Cero: 3\n","  - Fase de Evaluación:\n","    - Split Evaluación: 132 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=230.76, RMSE=300.49, R²=0.3895\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.3895) no supera el umbral (0.69).\n","\n","Procesando Grupo 93/108: organic/RichmondNorfolk...\n","  - Total: 169, No Cero: 164, Cero: 5\n","  - Fase de Evaluación:\n","    - Split Evaluación: 131 train / 33 test\n","    - Resultados Evaluación (Test Set): MAE=638.52, RMSE=889.54, R²=0.4712\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4712) no supera el umbral (0.69).\n","\n","Procesando Grupo 94/108: organic/Roanoke...\n","  - Total: 169, No Cero: 166, Cero: 3\n","  - Fase de Evaluación:\n","    - Split Evaluación: 132 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=920.29, RMSE=1,211.62, R²=0.5626\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5626) no supera el umbral (0.69).\n","\n","Procesando Grupo 95/108: organic/Sacramento...\n","  - Total: 169, No Cero: 48, Cero: 121\n","  - OMITIDO IMPUTACIÓN: Proporción de ceros >= 50% (71.6%).\n","\n","Procesando Grupo 96/108: organic/SanDiego...\n","  - Total: 169, No Cero: 87, Cero: 82\n","  - Fase de Evaluación:\n","    - Split Evaluación: 69 train / 18 test\n","    - Resultados Evaluación (Test Set): MAE=1,046.84, RMSE=1,658.50, R²=-0.2864\n","  - Fase de Imputación:\n","    - OMITIDA: R² (-0.2864) no supera el umbral (0.69).\n","\n","Procesando Grupo 97/108: organic/SanFrancisco...\n","  - Total: 169, No Cero: 67, Cero: 102\n","  - OMITIDO IMPUTACIÓN: Proporción de ceros >= 50% (60.4%).\n","\n","Procesando Grupo 98/108: organic/Seattle...\n","  - Total: 169, No Cero: 167, Cero: 2\n","  - Fase de Evaluación:\n","    - Split Evaluación: 133 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=6,815.98, RMSE=11,874.92, R²=0.4774\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.4774) no supera el umbral (0.69).\n","\n","Procesando Grupo 99/108: organic/SouthCarolina...\n","  - Total: 169, No Cero: 168, Cero: 1\n","  - Fase de Evaluación:\n","    - Split Evaluación: 134 train / 34 test\n","    - Resultados Evaluación (Test Set): MAE=437.05, RMSE=736.72, R²=0.5620\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5620) no supera el umbral (0.69).\n","\n","Procesando Grupo 100/108: organic/SouthCentral...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 101/108: organic/Southeast...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 102/108: organic/Spokane...\n","  - Total: 169, No Cero: 161, Cero: 8\n","  - Fase de Evaluación:\n","    - Split Evaluación: 128 train / 33 test\n","    - Resultados Evaluación (Test Set): MAE=540.03, RMSE=930.08, R²=0.5029\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.5029) no supera el umbral (0.69).\n","\n","Procesando Grupo 103/108: organic/StLouis...\n","  - Total: 169, No Cero: 143, Cero: 26\n","  - Fase de Evaluación:\n","    - Split Evaluación: 114 train / 29 test\n","    - Resultados Evaluación (Test Set): MAE=790.37, RMSE=1,006.41, R²=0.7621\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7621) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 143 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","Procesando Grupo 104/108: organic/Syracuse...\n","  - Total: 169, No Cero: 102, Cero: 67\n","  - Fase de Evaluación:\n","    - Split Evaluación: 81 train / 21 test\n","    - Resultados Evaluación (Test Set): MAE=455.80, RMSE=554.39, R²=0.6714\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.6714) no supera el umbral (0.69).\n","\n","Procesando Grupo 105/108: organic/Tampa...\n","  - Total: 169, No Cero: 100, Cero: 69\n","  - Fase de Evaluación:\n","    - Split Evaluación: 80 train / 20 test\n","    - Resultados Evaluación (Test Set): MAE=536.49, RMSE=1,220.34, R²=0.2624\n","  - Fase de Imputación:\n","    - OMITIDA: R² (0.2624) no supera el umbral (0.69).\n","\n","Procesando Grupo 106/108: organic/TotalUS...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 107/108: organic/West...\n","  - Total: 169, No Cero: 169, Cero: 0\n","  - OK: No hay ceros que imputar en este grupo.\n","\n","Procesando Grupo 108/108: organic/WestTexNewMexico...\n","  - Total: 166, No Cero: 154, Cero: 12\n","  - Fase de Evaluación:\n","    - Split Evaluación: 123 train / 31 test\n","    - Resultados Evaluación (Test Set): MAE=650.69, RMSE=1,140.10, R²=0.7530\n","  - Fase de Imputación:\n","    - PROCEDIENDO: R² (0.7530) > umbral (0.69).\n","    - Re-entrenando KNN con TODOS los 154 datos no cero...\n","  - ERROR Inesperado (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","--- Proceso de Evaluación e Imputación Condicional Finalizado ---\n","Se guardaron predicciones en 'KNN_Prediction' para un total de 0 puntos (ceros originales).\n","Para los demás ceros, o grupos omitidos, 'KNN_Prediction' contendrá NaN.\n","\n","Resumen de Resultados de la Fase de Evaluación (Solo grupos evaluados):\n","            type               region  n_non_zero  n_train_eval  n_test_eval  MAE_eval  RMSE_eval  R2_eval\n","2   conventional     BuffaloRochester         115            92           23   2689.22    6004.04   0.8787\n","36       organic        PhoenixTucson         161           128           33    206.38     322.54   0.8491\n","24       organic   HarrisburgScranton          93            74           19    351.92     597.17   0.8398\n","11  conventional              Spokane         122            97           25   1555.34    2749.31   0.7981\n","13  conventional             Syracuse         113            90           23   1363.87    2871.12   0.7855\n","5   conventional        PhoenixTucson         158           126           32  29169.37   40252.16   0.7786\n","46       organic              StLouis         143           114           29    790.37    1006.41   0.7621\n","49       organic     WestTexNewMexico         154           123           31    650.69    1140.10   0.7530\n","15       organic  BaltimoreWashington         133           106           27    500.69    1188.88   0.7525\n","31       organic    MiamiFtLauderdale         107            85           22    200.89     340.89   0.7212\n","4   conventional   NorthernNewEngland         122            97           25   5665.93   10962.41   0.6757\n","47       organic             Syracuse         102            81           21    455.80     554.39   0.6714\n","8   conventional              Roanoke         149           119           30   2008.02    3735.08   0.6642\n","22       organic        DallasFtWorth         128           102           26    503.74     815.84   0.6626\n","12  conventional              StLouis         153           122           31   4565.90    6237.72   0.6260\n","1   conventional               Boston         162           129           33   3872.46    7893.32   0.6002\n","37       organic           Pittsburgh         140           112           28    102.03     159.50   0.5772\n","10  conventional              Seattle         155           124           31  22065.39   46409.69   0.5696\n","41       organic              Roanoke         166           132           34    920.29    1211.62   0.5626\n","44       organic        SouthCarolina         168           134           34    437.05     736.72   0.5620\n","20       organic            Charlotte          97            77           20     81.61     121.95   0.5485\n","7   conventional      RichmondNorfolk         150           120           30   1641.26    2712.97   0.5319\n","45       organic              Spokane         161           128           33    540.03     930.08   0.5029\n","33       organic              NewYork         122            97           25    949.51    2427.92   0.4997\n","14       organic              Atlanta         168           134           34   1829.63    3064.93   0.4983\n","28       organic             LasVegas         147           117           30    424.51     751.55   0.4967\n","35       organic         Philadelphia         113            90           23    863.47    1772.24   0.4948\n","0   conventional                Boise         142           113           29   2048.73    4168.67   0.4906\n","43       organic              Seattle         167           133           34   6815.98   11874.92   0.4774\n","40       organic      RichmondNorfolk         164           131           33    638.52     889.54   0.4712\n","18       organic     BuffaloRochester         118            94           24   1585.73    1933.59   0.4518\n","30       organic           Louisville         167           133           34    657.31    1237.35   0.4406\n","17       organic               Boston         112            89           23    722.92     945.13   0.4378\n","27       organic         Jacksonville          88            70           18    737.95     941.43   0.4009\n","29       organic           LosAngeles         134           107           27   2340.26    3448.73   0.3962\n","21       organic             Columbus         168           134           34   1601.94    2340.57   0.3939\n","39       organic    RaleighGreensboro         166           132           34    230.76     300.49   0.3895\n","9   conventional           Sacramento         119            95           24    459.21     616.70   0.3634\n","6   conventional             Portland         167           133           34  15468.17   32754.67   0.3301\n","16       organic                Boise         166           132           34    628.95    1093.43   0.3181\n","38       organic             Portland         168           134           34   5799.13    8900.39   0.2970\n","48       organic                Tampa         100            80           20    536.49    1220.34   0.2624\n","34       organic              Orlando         102            81           21    584.43     920.51   0.2590\n","32       organic     NewOrleansMobile         108            86           22    211.47     349.48   0.1901\n","26       organic              Houston         103            82           21    876.55    1720.86   0.0935\n","19       organic           California         137           109           28   2707.61    4475.76  -0.1585\n","42       organic             SanDiego          87            69           18   1046.84    1658.50  -0.2864\n","3   conventional  HartfordSpringfield         168           134           34   1837.34    3696.25  -1.5861\n","25       organic  HartfordSpringfield          89            71           18     92.90     115.61  -2.8255\n","23       organic          GrandRapids          87            69           18    112.95     308.46 -11.6410\n"]}]},{"cell_type":"code","source":["\n","# Importar bibliotecas necesarias\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import gc # Para limpieza de memoria\n","\n","# Modelos, preprocesamiento y métricas de Scikit-learn\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","\n","# ¡¡NUEVO!! Importaciones para gráficos\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","\n","# --- Configuración ---\n","TEST_SIZE = 0.20\n","RANDOM_STATE = 42\n","MIN_SAMPLES_FOR_EVAL = 10\n","N_NEIGHBORS_KNN = 5\n","\n","# --- Preparación de df2 (Asegúrate que esta sección esté completa y funcione) ---\n","# [COPIAR AQUÍ LA SECCIÓN DE PREPARACIÓN DE df2 DEL SCRIPT ANTERIOR]\n","# --- Inicio de sección copiada ---\n","if 'df2' not in locals() or not isinstance(df2, pd.DataFrame):\n","    print(\"Error: El DataFrame 'df2' no está definido. Cárgalo primero.\"); exit()\n","else:\n","    print(\"Usando el DataFrame 'df2' existente.\")\n","\n","print(\"\\nPreparando datos en df2 (índice, tipos numéricos, features de tiempo)...\")\n","try:\n","    # Asegurar índice Date\n","    if not isinstance(df2.index, pd.DatetimeIndex):\n","        if 'Date' in df2.columns:\n","             df2['Date'] = pd.to_datetime(df2['Date'])\n","             df2.set_index('Date', inplace=True)\n","             df2.sort_index(inplace=True)\n","        elif not isinstance(df2.index, pd.DatetimeIndex):\n","             df2.index = pd.to_datetime(df2.index)\n","             df2.sort_index(inplace=True)\n","        else:\n","             df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime preparado y ordenado.\")\n","    elif not df2.index.is_monotonic_increasing:\n","        df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime ordenado.\")\n","\n","    # Crear Features de Tiempo para KNN\n","    if 'Fecha_Ordinal' not in df2.columns:\n","        df2['Fecha_Ordinal'] = df2.index.map(datetime.date.toordinal)\n","        print(\"  - Creada columna 'Fecha_Ordinal'.\")\n","    if 'Mes' not in df2.columns:\n","        df2['Mes'] = df2.index.month\n","        print(\"  - Creada columna 'Mes'.\")\n","    if 'SemanaDelAno' not in df2.columns:\n","        df2['SemanaDelAno'] = df2.index.isocalendar().week.astype(np.int32)\n","        print(\"  - Creada columna 'SemanaDelAno'.\")\n","except Exception as e:\n","    print(f\"Error durante la preparación de datos: {e}\"); exit()\n","\n","cols_to_check = ['Large Bags', 'Total Bags', 'Total Volume', 'AveragePrice']\n","print(f\"Asegurando que {cols_to_check} sean numéricas y rellenando NaNs con 0...\")\n","for col in cols_to_check:\n","    if col in df2.columns:\n","         if not pd.api.types.is_numeric_dtype(df2[col]):\n","              print(f\"  - Convirtiendo '{col}' a numérico...\")\n","              df2[col] = pd.to_numeric(df2[col], errors='coerce')\n","         if df2[col].isnull().any():\n","              print(f\"  - Rellenando NaNs en '{col}' con 0...\")\n","              df2[col] = df2[col].fillna(0)\n","\n","print(\"Optimizando tipos de datos...\")\n","try:\n","    if 'region' in df2.columns: df2['region'] = df2['region'].astype('category')\n","    if 'type' in df2.columns: df2['type'] = df2['type'].astype('category')\n","    for col in df2.select_dtypes(include=['float64']).columns:\n","       # Evitar convertir la columna de predicción si ya existe (aunque no se usará aquí)\n","       # if col != 'KNN_Prediction' or not ('KNN_Prediction' in df2 and df2[col].isnull().any()):\n","          df2[col] = df2[col].astype(np.float32)\n","    for col in df2.select_dtypes(include=['int64']).columns:\n","        if df2[col].min() >= np.iinfo(np.int32).min and df2[col].max() <= np.iinfo(np.int32).max:\n","             df2[col] = df2[col].astype(np.int32)\n","    print(\"Optimización de tipos completada.\")\n","except Exception as e_opt: print(f\"Advertencia durante optimización de tipos: {e_opt}\")\n","# --- Fin de sección copiada ---\n","\n","\n","# --- Evaluación del Modelo KNN por Grupo con Split Train/Test ---\n","print(f\"\\n--- Iniciando Evaluación de KNN para 'Large Bags' (Split {((1-TEST_SIZE)*100):.0f}% Entrenamiento / {TEST_SIZE*100:.0f}% Prueba) ---\")\n","\n","evaluation_results = []\n","required_loop_cols = ['type', 'region', 'Large Bags', 'Fecha_Ordinal', 'Mes', 'SemanaDelAno']\n","if not all(col in df2.columns for col in required_loop_cols):\n","      print(f\"Error: Faltan columnas necesarias ({required_loop_cols}) en df2.\"); exit()\n","\n","total_grupos = len(df2.groupby(['type', 'region']))\n","grupo_actual = 0\n","\n","for (tipo, region), group_df in df2.groupby(['type', 'region']):\n","    grupo_actual += 1\n","    print(f\"\\nProcesando Grupo {grupo_actual}/{total_grupos}: {tipo}/{region}...\")\n","\n","    # Variables para limpieza\n","    knn_reg = None; scaler = None; y_pred = None; X = None; y = None; X_train = None; X_test = None; y_train = None; y_test = None\n","    X_train_scaled = None; X_test_scaled = None; non_zero_data = None; r2 = np.nan # Inicializar r2\n","\n","    try:\n","        # 1. Seleccionar datos no cero\n","        non_zero_data = group_df[group_df['Large Bags'] > 0].copy()\n","        n_non_zero = len(non_zero_data)\n","        print(f\"  - Muestras con 'Large Bags' > 0: {n_non_zero}\")\n","\n","        # 2. Verificar suficientes datos\n","        if n_non_zero < MIN_SAMPLES_FOR_EVAL:\n","            print(f\"  - OMITIDO: Insuficientes muestras no cero ({n_non_zero} < {MIN_SAMPLES_FOR_EVAL}) para evaluar.\")\n","            continue\n","\n","        # 3. Preparar Features (X) y Target (y)\n","        features = ['Fecha_Ordinal', 'Mes', 'SemanaDelAno']\n","        X = non_zero_data[features]\n","        y = non_zero_data['Large Bags']\n","\n","        # 4. Dividir en Entrenamiento y Prueba\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n","        )\n","        print(f\"  - Split: {len(X_train)} entrenamiento / {len(X_test)} prueba\")\n","\n","        # 5. Escalar Características\n","        scaler = StandardScaler()\n","        X_train_scaled = scaler.fit_transform(X_train)\n","        X_test_scaled = scaler.transform(X_test)\n","\n","        # 6. Entrenar KNN\n","        knn_reg = KNeighborsRegressor(n_neighbors=N_NEIGHBORS_KNN, weights='distance')\n","        knn_reg.fit(X_train_scaled, y_train)\n","        print(f\"  - Modelo KNN entrenado (k={N_NEIGHBORS_KNN}).\")\n","\n","        # 7. Predecir en Prueba\n","        y_pred = knn_reg.predict(X_test_scaled)\n","        y_pred = np.maximum(0, y_pred) # Ajustar negativos\n","\n","        # 8. Evaluar\n","        mae = mean_absolute_error(y_test, y_pred)\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        r2 = knn_reg.score(X_test_scaled, y_test) # Usar .score() para R²\n","\n","        print(f\"  - EVALUACIÓN (Prueba):\")\n","        print(f\"    - MAE : {mae:,.2f}\")\n","        print(f\"    - RMSE: {rmse:,.2f}\")\n","        print(f\"    - R²  : {r2:.4f}\")\n","\n","        # Guardar resultados\n","        evaluation_results.append({\n","            'type': tipo, 'region': region, 'n_non_zero': n_non_zero, 'n_train': len(X_train),\n","            'n_test': len(X_test), 'MAE': mae, 'RMSE': rmse, 'R2': r2\n","        })\n","\n","        # --- 9. NUEVO: Graficar Comparación Actual vs Predicción ---\n","        # Solo intentar graficar si hay datos de prueba\n","        if not X_test.empty:\n","            print(f\"  - Generando gráfico de dispersión Actual vs. Predicción...\")\n","            try:\n","                plt.figure(figsize=(14, 7)) # Nueva figura para este grupo\n","\n","                # Graficar valores reales del conjunto de prueba (azules)\n","                plt.scatter(X_test.index, y_test,\n","                            color='blue', label='Valor Real (Prueba)', alpha=0.6, s=50, marker='o')\n","\n","                # Graficar predicciones para el conjunto de prueba (naranjas)\n","                plt.scatter(X_test.index, y_pred,\n","                            color='orange', label='Predicción KNN', marker='x', s=50)\n","\n","                # Título y etiquetas\n","                plt.title(f\"Comparación Real vs. Predicción KNN - Large Bags\\n{tipo.capitalize()} / {region} (Test Set, R²={r2:.3f})\", fontsize=14)\n","                plt.xlabel(\"Fecha\", fontsize=12)\n","                plt.ylabel(\"Large Bags\", fontsize=12)\n","                plt.legend()\n","                plt.grid(True, axis='y', linestyle=':') # Rejilla horizontal suave\n","\n","                # Formatear eje de fechas para mejor lectura\n","                plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d')) # Formato más específico\n","                plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator(minticks=5, maxticks=10)) # Ajustar número de ticks\n","                plt.gcf().autofmt_xdate() # Rotar/ajustar fechas automáticamente\n","\n","                plt.tight_layout() # Ajustar para evitar solapamiento de etiquetas\n","                plt.show() # Mostrar el gráfico para este grupo\n","\n","            except Exception as e_plot:\n","                print(f\"  - ERROR al generar gráfico ({type(e_plot).__name__}: {e_plot}).\")\n","        else:\n","             print(\"  - No hay datos de prueba para graficar.\")\n","\n","\n","    except Exception as e:\n","        print(f\"  - ERROR durante la evaluación ({type(e).__name__}: {str(e)[:100]}...).\")\n","\n","    finally:\n","         # Limpieza de Memoria\n","         variables_a_borrar = ['group_df', 'non_zero_data', 'X', 'y',\n","                               'X_train', 'X_test', 'y_train', 'y_test',\n","                               'X_train_scaled', 'X_test_scaled', 'knn_reg', 'scaler', 'y_pred']\n","         for var_name in variables_a_borrar:\n","              try:\n","                  if var_name in locals(): del locals()[var_name]\n","              except NameError: pass\n","         # gc.collect()\n","\n","print(f\"\\n--- Evaluación de KNN finalizada para todos los grupos ---\")\n","\n","# --- Opcional: Mostrar Resultados Consolidados ---\n","if evaluation_results:\n","    results_df = pd.DataFrame(evaluation_results)\n","    print(\"\\nResumen de Resultados de Evaluación (Ordenado por R² descendente):\")\n","    pd.set_option('display.max_rows', None); pd.set_option('display.max_columns', None); pd.set_option('display.width', 120)\n","    print(results_df.sort_values(by='R2', ascending=False).round({'MAE': 2, 'RMSE': 2, 'R2': 4}))\n","    pd.reset_option('display.max_rows'); pd.reset_option('display.max_columns'); pd.reset_option('display.width')\n","else:\n","    print(\"\\nNo se generaron resultados de evaluación.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1-PdPu_j9GVieO1_MCrdad9xK999nzp-j"},"collapsed":true,"id":"2YudaOwdSaOm","executionInfo":{"status":"ok","timestamp":1745745176934,"user_tz":-120,"elapsed":25577,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}},"outputId":"fd7a04a9-7471-4ebe-8aff-f860a288fd54"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["\n","# Importar bibliotecas necesarias\n","import pandas as pd\n","import numpy as np\n","# ¡Importante! Modelos y preprocesamiento de Scikit-learn\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.preprocessing import StandardScaler # Para escalar características\n","import io\n","import datetime\n","import gc # Para limpieza de memoria\n","\n","# --- Definir nombre para la nueva columna de predicciones ---\n","COLUMNA_PREDICCION = 'KNN_Prediction'\n","\n","# --- Preparación ---\n","# **¡ASEGÚRATE DE QUE df2 CONTENGA TUS DATOS ANTES DE EJECUTAR ESTO!**\n","if 'df2' not in locals() or not isinstance(df2, pd.DataFrame):\n","    print(\"Error: El DataFrame 'df2' no está definido. Cárgalo primero.\"); exit()\n","else:\n","    print(\"Usando el DataFrame 'df2' existente.\")\n","\n","# --- Preparación de Datos en df2 ---\n","print(\"\\nPreparando datos en df2 (índice, tipos numéricos, features de tiempo)...\")\n","try:\n","    # Asegurar índice Date\n","    if not isinstance(df2.index, pd.DatetimeIndex):\n","        if 'Date' in df2.columns:\n","             # Convertir Date a datetime, establecer como índice y ordenar\n","             df2['Date'] = pd.to_datetime(df2['Date'])\n","             df2.set_index('Date', inplace=True)\n","             df2.sort_index(inplace=True)\n","        # Si 'Date' no es columna pero el índice no es DatetimeIndex, intentar convertir índice\n","        elif not isinstance(df2.index, pd.DatetimeIndex):\n","             df2.index = pd.to_datetime(df2.index)\n","             df2.sort_index(inplace=True)\n","        else: # Si ya es DatetimeIndex pero no está ordenado\n","             df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime preparado y ordenado.\")\n","    elif not df2.index.is_monotonic_increasing: # Si es DatetimeIndex pero no ordenado\n","        df2.sort_index(inplace=True)\n","        print(\"  - Índice Datetime ordenado.\")\n","\n","\n","    # *** NUEVO: Crear Features de Tiempo para KNN ***\n","    # Necesitamos características numéricas que capturen la tendencia y estacionalidad\n","    if 'Fecha_Ordinal' not in df2.columns:\n","        df2['Fecha_Ordinal'] = df2.index.map(datetime.date.toordinal)\n","        print(\"  - Creada columna 'Fecha_Ordinal'.\")\n","    # Usaremos Semana del Año y Mes para capturar estacionalidad\n","    if 'Mes' not in df2.columns:\n","        df2['Mes'] = df2.index.month\n","        print(\"  - Creada columna 'Mes'.\")\n","    if 'SemanaDelAno' not in df2.columns:\n","        df2['SemanaDelAno'] = df2.index.isocalendar().week.astype(np.int32) # Usar tipo más eficiente\n","        print(\"  - Creada columna 'SemanaDelAno'.\")\n","\n","except Exception as e:\n","    print(f\"Error durante la preparación de datos: {e}\"); exit()\n","\n","# Asegurar columnas numéricas clave y rellenar NaNs con 0\n","cols_to_check = ['Large Bags', 'Total Bags', 'Total Volume', 'AveragePrice'] # Añadir AveragePrice por si acaso\n","print(f\"Asegurando que {cols_to_check} sean numéricas y rellenando NaNs con 0...\")\n","for col in cols_to_check:\n","    if col in df2.columns:\n","         if not pd.api.types.is_numeric_dtype(df2[col]):\n","              print(f\"  - Convirtiendo '{col}' a numérico...\")\n","              df2[col] = pd.to_numeric(df2[col], errors='coerce')\n","         if df2[col].isnull().any():\n","              print(f\"  - Rellenando NaNs en '{col}' con 0...\")\n","              df2[col] = df2[col].fillna(0)\n","    # else: # No imprimir advertencia si no existen\n","         # print(f\"Advertencia: La columna '{col}' no se encontró en df2.\")\n","\n","# Optimización de tipos (opcional pero recomendado)\n","print(\"Optimizando tipos de datos...\")\n","try:\n","    if 'region' in df2.columns: df2['region'] = df2['region'].astype('category')\n","    if 'type' in df2.columns: df2['type'] = df2['type'].astype('category')\n","    # Convertir floats a float32\n","    for col in df2.select_dtypes(include=['float64']).columns:\n","        # Evitar convertir la columna de predicción si ya existe y es float64 con NaNs\n","        if col != COLUMNA_PREDICCION or not df2[col].isnull().any():\n","           df2[col] = df2[col].astype(np.float32)\n","    # Convertir ints a int32 si caben\n","    for col in df2.select_dtypes(include=['int64']).columns:\n","        if df2[col].min() >= np.iinfo(np.int32).min and df2[col].max() <= np.iinfo(np.int32).max:\n","             df2[col] = df2[col].astype(np.int32)\n","    print(\"Optimización de tipos completada.\")\n","except Exception as e_opt: print(f\"Advertencia durante optimización de tipos: {e_opt}\")\n","\n","\n","# --- Imputación por Grupo con KNeighborsRegressor en df2 ---\n","print(\"\\n--- Iniciando proceso de imputación para 'Large Bags' con KNeighborsRegressor en df2 ---\")\n","print(f\"--- Las predicciones se guardarán en la columna '{COLUMNA_PREDICCION}' ---\")\n","\n","# *** NUEVO: Inicializar la columna de predicciones con NaN ***\n","df2[COLUMNA_PREDICCION] = np.nan\n","\n","# KNN necesita algunos vecinos, pongamos un mínimo razonable\n","min_train_samples = 10 # Número mínimo de filas con Large Bags > 0 para entrenar KNN\n","print(f\"Umbral mínimo de muestras de entrenamiento (>0): {min_train_samples}\")\n","n_neighbors_knn = 5 # Número de vecinos a considerar por KNN\n","print(f\"Número de vecinos (k) para KNN: {n_neighbors_knn}\")\n","indices_imputados_global = set() # Mantenemos registro de qué índices recibieron predicción\n","\n","# Asegurar columnas antes del bucle\n","required_loop_cols = ['type', 'region', 'Large Bags', 'Fecha_Ordinal', 'Mes', 'SemanaDelAno']\n","if not all(col in df2.columns for col in required_loop_cols):\n","      print(f\"Error: Faltan columnas necesarias ({required_loop_cols}) en df2.\"); exit()\n","\n","# --- Bucle Principal por Grupo ---\n","total_grupos = len(df2.groupby(['type', 'region']))\n","grupo_actual = 0\n","for (tipo, region), group_df in df2.groupby(['type', 'region']):\n","    grupo_actual += 1\n","    print(f\"Procesando Grupo {grupo_actual}/{total_grupos}: {tipo}/{region}...\", end=' ')\n","\n","    # Definir variables que podrían crearse dentro del try para borrar en finally\n","    knn_reg = None; scaler = None; predicciones = None; predicciones_ajustadas = None\n","    X_train = None; y_train = None; X_impute = None; X_train_scaled = None; X_impute_scaled = None\n","    datos_entrenamiento = None; datos_imputar = None\n","\n","    try:\n","        total_rows_group = len(group_df)\n","        if total_rows_group == 0: continue # Saltar si el grupo está vacío por alguna razón\n","\n","        # Separar datos entrenamiento (>0) e imputación (==0)\n","        mask_train = group_df['Large Bags'] > 0\n","        mask_impute = group_df['Large Bags'] == 0\n","        datos_entrenamiento = group_df.loc[mask_train]\n","        datos_imputar = group_df.loc[mask_impute]\n","        zero_rows_group = len(datos_imputar)\n","\n","        # Chequeo >= 50% ceros\n","        proportion_zeros = zero_rows_group / total_rows_group if total_rows_group > 0 else 0\n","        if proportion_zeros >= 0.5:\n","             print(f\" Omitido ({proportion_zeros*100:.1f}% ceros).\"); continue\n","\n","        # Chequeo datos entrenamiento suficientes para KNN (necesita al menos k vecinos)\n","        if len(datos_entrenamiento) < min_train_samples or len(datos_entrenamiento) < n_neighbors_knn:\n","             print(f\" Omitido (Insuf. Train: {len(datos_entrenamiento)} < {max(min_train_samples, n_neighbors_knn)}).\"); continue\n","\n","        # Chequeo si hay algo que imputar (aunque no supere el 50% de ceros)\n","        if datos_imputar.empty:\n","             print(\" OK (No hay ceros que imputar).\"); continue\n","\n","        print(f\" Entrenando con {len(datos_entrenamiento)}, prediciendo para {zero_rows_group} ceros...\", end=' ')\n","\n","        # Preparar Features (X) y Target (y)\n","        # Usamos Fecha_Ordinal (tendencia), Mes y SemanaDelAno (estacionalidad)\n","        features = ['Fecha_Ordinal', 'Mes', 'SemanaDelAno']\n","        X_train = datos_entrenamiento[features]\n","        y_train = datos_entrenamiento['Large Bags']\n","        X_impute = datos_imputar[features]\n","\n","        # Escalar las características (MUY importante para KNN)\n","        scaler = StandardScaler()\n","        X_train_scaled = scaler.fit_transform(X_train)\n","        X_impute_scaled = scaler.transform(X_impute) # Solo transformar con el scaler ajustado a train\n","\n","        # Crear y entrenar el modelo KNeighborsRegressor\n","        # weights='distance' -> vecinos más cercanos tienen más influencia\n","        knn_reg = KNeighborsRegressor(n_neighbors=n_neighbors_knn, weights='distance')\n","        knn_reg.fit(X_train_scaled, y_train)\n","\n","        # Predecir los valores para los ceros\n","        predicciones = knn_reg.predict(X_impute_scaled)\n","\n","        # Ajustar predicciones negativas a 0\n","        predicciones_ajustadas = np.maximum(0, predicciones) # predict devuelve numpy array\n","\n","        # Obtener índices originales para actualizar df2\n","        indices_imputar = datos_imputar.index\n","\n","        # *** NUEVO: Guardar la predicción ajustada en la nueva columna ***\n","        df2.loc[indices_imputar, COLUMNA_PREDICCION] = predicciones_ajustadas\n","        indices_imputados_global.update(indices_imputar) # Actualizar conjunto de índices donde se hizo predicción\n","\n","        # --- NO SOBRESCRIBIR 'Large Bags' ---\n","        # Ahora que guardamos la predicción, no necesitamos (ni queremos)\n","        # sobrescribir la columna original 'Large Bags' aquí.\n","        # El siguiente script usará 'Large Bags' y 'KNN_Prediction' para crear 'Large Bags Filled'.\n","        # df2.loc[indices_imputar, 'Large Bags'] = predicciones_ajustadas # <-- COMENTADO/ELIMINADO\n","\n","        # --- NO ACTUALIZAR TOTALES AQUÍ ---\n","        # Es más lógico actualizar los totales cuando se crea 'Large Bags Filled'\n","        # if 'Total Bags' in df2.columns: df2.loc[indices_imputar, 'Total Bags'] += predicciones_ajustadas # <-- COMENTADO\n","        # if 'Total Volume' in df2.columns: df2.loc[indices_imputar, 'Total Volume'] += predicciones_ajustadas # <-- COMENTADO\n","\n","        print(f\" Predicciones guardadas para {len(indices_imputar)} puntos.\")\n","\n","    except Exception as e:\n","        print(f\" ERROR ({type(e).__name__}: {str(e)[:100]}...).\")\n","        # Considerar añadir 'continue' si quieres que el bucle siga con el siguiente grupo tras un error\n","\n","    finally:\n","         # Limpieza de Memoria al final de CADA iteración\n","         variables_a_borrar = ['group_df', 'datos_entrenamiento', 'datos_imputar',\n","                               'X_train', 'y_train', 'X_impute', 'X_train_scaled',\n","                               'X_impute_scaled', 'knn_reg', 'scaler',\n","                               'predicciones', 'predicciones_ajustadas']\n","         for var_name in variables_a_borrar:\n","              # Usar try-except por si alguna variable no llegó a definirse antes de un error\n","              try:\n","                  if var_name in locals(): del locals()[var_name]\n","              except NameError: pass # Ignorar si la variable no existe\n","         # Llamar al recolector de basura explícitamente\n","         # collected = gc.collect() # Descomentar si realmente tienes problemas graves de memoria\n","\n","print(f\"\\n--- Proceso de generación de predicciones KNN en df2 finalizado ---\")\n","print(f\"Se generaron predicciones para {len(indices_imputados_global)} puntos en total.\")\n","print(f\"La columna '{COLUMNA_PREDICCION}' ahora contiene las predicciones (o NaN si no se aplicó).\")\n","print(\"La columna 'Large Bags' original NO ha sido modificada.\")\n","\n","# --- Limpieza Opcional: Eliminar columnas auxiliares de fecha ---\n","# Considera si las necesitarás más adelante antes de borrarlas\n","# df2 = df2.drop(columns=['Fecha_Ordinal', 'Mes', 'SemanaDelAno'], errors='ignore')\n","# print(\"Columnas auxiliares de fecha eliminadas.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wd1Ty-E835bh","executionInfo":{"status":"ok","timestamp":1745745177266,"user_tz":-120,"elapsed":255,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}},"outputId":"2b913125-5d15-41ee-ff8f-a7ad59e972a2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Usando el DataFrame 'df2' existente.\n","\n","Preparando datos en df2 (índice, tipos numéricos, features de tiempo)...\n","Asegurando que ['Large Bags', 'Total Bags', 'Total Volume', 'AveragePrice'] sean numéricas y rellenando NaNs con 0...\n","Optimizando tipos de datos...\n","Optimización de tipos completada.\n","\n","--- Iniciando proceso de imputación para 'Large Bags' con KNeighborsRegressor en df2 ---\n","--- Las predicciones se guardarán en la columna 'KNN_Prediction' ---\n","Umbral mínimo de muestras de entrenamiento (>0): 10\n","Número de vecinos (k) para KNN: 5\n","Procesando Grupo 1/108: conventional/Albany...  OK (No hay ceros que imputar).\n","Procesando Grupo 2/108: conventional/Atlanta...  OK (No hay ceros que imputar).\n","Procesando Grupo 3/108: conventional/BaltimoreWashington...  OK (No hay ceros que imputar).\n","Procesando Grupo 4/108: conventional/Boise...  Entrenando con 142, prediciendo para 27 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 5/108: conventional/Boston...  Entrenando con 162, prediciendo para 7 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 6/108: conventional/BuffaloRochester...  Entrenando con 115, prediciendo para 54 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 7/108: conventional/California...  OK (No hay ceros que imputar).\n","Procesando Grupo 8/108: conventional/Charlotte...  OK (No hay ceros que imputar).\n","Procesando Grupo 9/108: conventional/Chicago...  OK (No hay ceros que imputar).\n","Procesando Grupo 10/108: conventional/CincinnatiDayton...  OK (No hay ceros que imputar).\n","Procesando Grupo 11/108: conventional/Columbus...  OK (No hay ceros que imputar).\n","Procesando Grupo 12/108: conventional/DallasFtWorth...  OK (No hay ceros que imputar).\n","Procesando Grupo 13/108: conventional/Denver...  OK (No hay ceros que imputar).\n","Procesando Grupo 14/108: conventional/Detroit...  OK (No hay ceros que imputar).\n","Procesando Grupo 15/108: conventional/GrandRapids...  OK (No hay ceros que imputar).\n","Procesando Grupo 16/108: conventional/GreatLakes...  OK (No hay ceros que imputar).\n","Procesando Grupo 17/108: conventional/HarrisburgScranton...  OK (No hay ceros que imputar).\n","Procesando Grupo 18/108: conventional/HartfordSpringfield...  Entrenando con 168, prediciendo para 1 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 19/108: conventional/Houston...  OK (No hay ceros que imputar).\n","Procesando Grupo 20/108: conventional/Indianapolis...  OK (No hay ceros que imputar).\n","Procesando Grupo 21/108: conventional/Jacksonville...  OK (No hay ceros que imputar).\n","Procesando Grupo 22/108: conventional/LasVegas...  OK (No hay ceros que imputar).\n","Procesando Grupo 23/108: conventional/LosAngeles...  OK (No hay ceros que imputar).\n","Procesando Grupo 24/108: conventional/Louisville...  OK (No hay ceros que imputar).\n","Procesando Grupo 25/108: conventional/MiamiFtLauderdale...  OK (No hay ceros que imputar).\n","Procesando Grupo 26/108: conventional/Midsouth...  OK (No hay ceros que imputar).\n","Procesando Grupo 27/108: conventional/Nashville...  OK (No hay ceros que imputar).\n","Procesando Grupo 28/108: conventional/NewOrleansMobile...  OK (No hay ceros que imputar).\n","Procesando Grupo 29/108: conventional/NewYork...  OK (No hay ceros que imputar).\n","Procesando Grupo 30/108: conventional/Northeast...  OK (No hay ceros que imputar).\n","Procesando Grupo 31/108: conventional/NorthernNewEngland...  Entrenando con 122, prediciendo para 47 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 32/108: conventional/Orlando...  OK (No hay ceros que imputar).\n","Procesando Grupo 33/108: conventional/Philadelphia...  OK (No hay ceros que imputar).\n","Procesando Grupo 34/108: conventional/PhoenixTucson...  Entrenando con 158, prediciendo para 11 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 35/108: conventional/Pittsburgh...  OK (No hay ceros que imputar).\n","Procesando Grupo 36/108: conventional/Plains...  OK (No hay ceros que imputar).\n","Procesando Grupo 37/108: conventional/Portland...  Entrenando con 167, prediciendo para 2 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 38/108: conventional/RaleighGreensboro...  OK (No hay ceros que imputar).\n","Procesando Grupo 39/108: conventional/RichmondNorfolk...  Entrenando con 150, prediciendo para 19 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 40/108: conventional/Roanoke...  Entrenando con 149, prediciendo para 20 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 41/108: conventional/Sacramento...  Entrenando con 119, prediciendo para 50 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 42/108: conventional/SanDiego...  OK (No hay ceros que imputar).\n","Procesando Grupo 43/108: conventional/SanFrancisco...  OK (No hay ceros que imputar).\n","Procesando Grupo 44/108: conventional/Seattle...  Entrenando con 155, prediciendo para 14 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 45/108: conventional/SouthCarolina...  OK (No hay ceros que imputar).\n","Procesando Grupo 46/108: conventional/SouthCentral...  OK (No hay ceros que imputar).\n","Procesando Grupo 47/108: conventional/Southeast...  OK (No hay ceros que imputar).\n","Procesando Grupo 48/108: conventional/Spokane...  Entrenando con 122, prediciendo para 47 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 49/108: conventional/StLouis...  Entrenando con 153, prediciendo para 16 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 50/108: conventional/Syracuse...  Entrenando con 113, prediciendo para 56 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 51/108: conventional/Tampa...  OK (No hay ceros que imputar).\n","Procesando Grupo 52/108: conventional/TotalUS...  OK (No hay ceros que imputar).\n","Procesando Grupo 53/108: conventional/West...  OK (No hay ceros que imputar).\n","Procesando Grupo 54/108: conventional/WestTexNewMexico...  OK (No hay ceros que imputar).\n","Procesando Grupo 55/108: organic/Albany...  Omitido (91.1% ceros).\n","Procesando Grupo 56/108: organic/Atlanta...  Entrenando con 168, prediciendo para 1 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 57/108: organic/BaltimoreWashington...  Entrenando con 133, prediciendo para 36 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 58/108: organic/Boise...  Entrenando con 166, prediciendo para 3 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 59/108: organic/Boston...  Entrenando con 112, prediciendo para 57 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 60/108: organic/BuffaloRochester...  Entrenando con 118, prediciendo para 51 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 61/108: organic/California...  Entrenando con 137, prediciendo para 32 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 62/108: organic/Charlotte...  Entrenando con 97, prediciendo para 72 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 63/108: organic/Chicago...  Omitido (74.0% ceros).\n","Procesando Grupo 64/108: organic/CincinnatiDayton...  OK (No hay ceros que imputar).\n","Procesando Grupo 65/108: organic/Columbus...  Entrenando con 168, prediciendo para 1 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 66/108: organic/DallasFtWorth...  Entrenando con 128, prediciendo para 41 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 67/108: organic/Denver...  OK (No hay ceros que imputar).\n","Procesando Grupo 68/108: organic/Detroit...  OK (No hay ceros que imputar).\n","Procesando Grupo 69/108: organic/GrandRapids...  Entrenando con 87, prediciendo para 82 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 70/108: organic/GreatLakes...  OK (No hay ceros que imputar).\n","Procesando Grupo 71/108: organic/HarrisburgScranton...  Entrenando con 93, prediciendo para 76 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 72/108: organic/HartfordSpringfield...  Entrenando con 89, prediciendo para 80 ceros... "]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-862c06b336d1>:111: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  total_grupos = len(df2.groupby(['type', 'region']))\n","<ipython-input-5-862c06b336d1>:113: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n","  for (tipo, region), group_df in df2.groupby(['type', 'region']):\n"]},{"output_type":"stream","name":"stdout","text":[" ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 73/108: organic/Houston...  Entrenando con 103, prediciendo para 66 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 74/108: organic/Indianapolis...  OK (No hay ceros que imputar).\n","Procesando Grupo 75/108: organic/Jacksonville...  Entrenando con 88, prediciendo para 81 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 76/108: organic/LasVegas...  Entrenando con 147, prediciendo para 22 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 77/108: organic/LosAngeles...  Entrenando con 134, prediciendo para 35 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 78/108: organic/Louisville...  Entrenando con 167, prediciendo para 2 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 79/108: organic/MiamiFtLauderdale...  Entrenando con 107, prediciendo para 62 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 80/108: organic/Midsouth...  OK (No hay ceros que imputar).\n","Procesando Grupo 81/108: organic/Nashville...  OK (No hay ceros que imputar).\n","Procesando Grupo 82/108: organic/NewOrleansMobile...  Entrenando con 108, prediciendo para 61 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 83/108: organic/NewYork...  Entrenando con 122, prediciendo para 47 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 84/108: organic/Northeast...  OK (No hay ceros que imputar).\n","Procesando Grupo 85/108: organic/NorthernNewEngland...  Omitido (88.8% ceros).\n","Procesando Grupo 86/108: organic/Orlando...  Entrenando con 102, prediciendo para 67 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 87/108: organic/Philadelphia...  Entrenando con 113, prediciendo para 56 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 88/108: organic/PhoenixTucson...  Entrenando con 161, prediciendo para 8 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 89/108: organic/Pittsburgh...  Entrenando con 140, prediciendo para 29 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 90/108: organic/Plains...  OK (No hay ceros que imputar).\n","Procesando Grupo 91/108: organic/Portland...  Entrenando con 168, prediciendo para 1 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 92/108: organic/RaleighGreensboro...  Entrenando con 166, prediciendo para 3 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 93/108: organic/RichmondNorfolk...  Entrenando con 164, prediciendo para 5 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 94/108: organic/Roanoke...  Entrenando con 166, prediciendo para 3 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 95/108: organic/Sacramento...  Omitido (71.6% ceros).\n","Procesando Grupo 96/108: organic/SanDiego...  Entrenando con 87, prediciendo para 82 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 97/108: organic/SanFrancisco...  Omitido (60.4% ceros).\n","Procesando Grupo 98/108: organic/Seattle...  Entrenando con 167, prediciendo para 2 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 99/108: organic/SouthCarolina...  Entrenando con 168, prediciendo para 1 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 100/108: organic/SouthCentral...  OK (No hay ceros que imputar).\n","Procesando Grupo 101/108: organic/Southeast...  OK (No hay ceros que imputar).\n","Procesando Grupo 102/108: organic/Spokane...  Entrenando con 161, prediciendo para 8 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 103/108: organic/StLouis...  Entrenando con 143, prediciendo para 26 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 104/108: organic/Syracuse...  Entrenando con 102, prediciendo para 67 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 105/108: organic/Tampa...  Entrenando con 100, prediciendo para 69 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","Procesando Grupo 106/108: organic/TotalUS...  OK (No hay ceros que imputar).\n","Procesando Grupo 107/108: organic/West...  OK (No hay ceros que imputar).\n","Procesando Grupo 108/108: organic/WestTexNewMexico...  Entrenando con 154, prediciendo para 12 ceros...  ERROR (ValueError: Must have equal len keys and value when setting with an iterable...).\n","\n","--- Proceso de generación de predicciones KNN en df2 finalizado ---\n","Se generaron predicciones para 0 puntos en total.\n","La columna 'KNN_Prediction' ahora contiene las predicciones (o NaN si no se aplicó).\n","La columna 'Large Bags' original NO ha sido modificada.\n"]}]},{"cell_type":"code","source":["\"\"\"\n","# --- BLOQUE DE CÓDIGO DE GRAFICACIÓN (ADAPTADO PARA KNN) ---\n","\n","# Importar KNN y Scaler para re-entrenar\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.dates as mdates\n","\n","\n","# --- Selección de Grupos y Generación de Gráficos ---\n","grupos_a_graficar = [\n","    ('conventional', 'BuffaloRochester'),\n","    ('organic', 'NewYork'),\n","    ('conventional', 'SanFrancisco'),\n","    # ('conventional', 'Nashville'),\n","    # ('conventional', 'West')\n","]\n","\n","# Verificar si las variables necesarias existen\n","if ('indices_imputados_global' not in locals() or 'df2' not in locals()\n","    or 'min_train_samples' not in locals() or 'n_neighbors_knn' not in locals()):\n","     print(\"Error: Variables de imputación no encontradas (df2, indices_imputados_global, etc.).\")\n","     print(\"Asegúrate de ejecutar el bloque de imputación KNN primero.\")\n","     exit()\n","else:\n","    print(f\"\\n--- Generando gráficos para {len(grupos_a_graficar)} grupos seleccionados usando KNN (datos de df2) ---\")\n","\n","    # Re-asegurar columnas necesarias para graficar\n","    if not all(col in df2.columns for col in ['type', 'region', 'Date', 'Large Bags', 'Fecha_Ordinal', 'Mes', 'SemanaDelAno']):\n","         print(\"Error: Faltan columnas necesarias para graficar en df2.\"); exit()\n","\n","    for tipo_plot, region_plot in grupos_a_graficar:\n","\n","        print(f\"\\nGenerando gráfico para: type='{tipo_plot}', region='{region_plot}'\")\n","\n","        df_grupo = df2[(df2['type'] == tipo_plot) & (df2['region'] == region_plot)].sort_index().copy()\n","\n","        if df_grupo.empty: print(\"   -> No hay datos para este grupo.\"); continue\n","\n","        indices_imputados_grupo = df_grupo.index.intersection(indices_imputados_global)\n","        mask_imputed = df_grupo.index.isin(indices_imputados_grupo)\n","        mask_original_nonzero = (df_grupo['Large Bags'] > 0)\n","        mask_original_zero_not_imputed = (~mask_original_nonzero) & (~mask_imputed)\n","\n","        # --- Re-entrenar el modelo KNN y predecir para todo el grupo (para la línea) ---\n","        train_data_plot = df_grupo[mask_original_nonzero]\n","\n","        knn_reg_plot = None\n","        pred_line = None\n","        pred_dates = None\n","        can_plot_line = False\n","\n","        # Comprobar si hay suficientes datos originales (>0) y si son suficientes para los vecinos k\n","        if len(train_data_plot) >= min_train_samples and len(train_data_plot) >= n_neighbors_knn:\n","            print(f\"   -> Re-entrenando modelo KNN con {len(train_data_plot)} puntos originales (>0).\")\n","            try:\n","                features = ['Fecha_Ordinal', 'Mes', 'SemanaDelAno']\n","                X_train_plot = train_data_plot[features]\n","                y_train_plot = train_data_plot['Large Bags']\n","                # Preparar features para TODOS los puntos del grupo para obtener la línea de predicción\n","                X_group_plot = df_grupo[features]\n","\n","                # Escalar\n","                scaler_plot = StandardScaler()\n","                X_train_plot_scaled = scaler_plot.fit_transform(X_train_plot)\n","                X_group_plot_scaled = scaler_plot.transform(X_group_plot) # Usar mismo scaler\n","\n","                # Entrenar\n","                knn_reg_plot = KNeighborsRegressor(n_neighbors=n_neighbors_knn, weights='distance')\n","                knn_reg_plot.fit(X_train_plot_scaled, y_train_plot)\n","\n","                # Predecir para todos los puntos del grupo\n","                pred_line_raw = knn_reg_plot.predict(X_group_plot_scaled)\n","                pred_line = np.maximum(0, pred_line_raw) # Cap negativos\n","                pred_dates = df_grupo.index # Fechas correspondientes\n","                can_plot_line = True\n","\n","            except Exception as e:\n","                print(f\"   -> Error al re-entrenar o predecir para la línea KNN: {e}\")\n","        else:\n","            print(f\"   -> No se puede trazar la línea KNN (datos originales > 0 son {len(train_data_plot)}, se necesitan {max(min_train_samples, n_neighbors_knn)}).\")\n","\n","        # --- Crear el Gráfico ---\n","        plt.figure(figsize=(15, 7))\n","\n","        plt.scatter(df_grupo.loc[mask_original_nonzero].index, df_grupo.loc[mask_original_nonzero, 'Large Bags'],\n","                    label='Original (>0)', alpha=0.6, color='blue', s=30)\n","        if not df_grupo.loc[mask_imputed].empty:\n","             plt.scatter(df_grupo.loc[mask_imputed].index, df_grupo.loc[mask_imputed, 'Large Bags'],\n","                         label='Imputado (Originalmente 0)', alpha=0.9, color='orange', marker='X', s=60)\n","        if not df_grupo.loc[mask_original_zero_not_imputed].empty:\n","              plt.scatter(df_grupo.loc[mask_original_zero_not_imputed].index, df_grupo.loc[mask_original_zero_not_imputed, 'Large Bags'],\n","                         label='Originalmente 0 (No Imputado)', alpha=0.7, color='red', marker='o', s=40)\n","\n","        # Graficar la línea de predicción KNN si se pudo calcular\n","        if can_plot_line and pred_line is not None and pred_dates is not None:\n","             # Crear un df temporal para ordenar por fecha antes de graficar linea\n","             line_df = pd.DataFrame({'Date': pred_dates, 'Prediction': pred_line}).sort_values(by='Date')\n","             plt.plot(line_df['Date'].dt.to_pydatetime(), line_df['Prediction'],\n","                      color='green', linestyle='--', linewidth=2, label=f'Predicción KNN (k={n_neighbors_knn})')\n","\n","        plt.title(f'Large Bags vs Tiempo (Imputado con KNN) - {tipo_plot.capitalize()} / {region_plot}')\n","        plt.xlabel('Fecha')\n","        plt.ylabel('Large Bags')\n","        plt.legend()\n","        plt.grid(True, axis='y', linestyle=':')\n","        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n","        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator(minticks=5, maxticks=10))\n","        plt.gcf().autofmt_xdate()\n","        plt.tight_layout()\n","        plt.show()\n","    \"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122},"id":"WqFl_RTR4Ea7","executionInfo":{"status":"ok","timestamp":1745745177272,"user_tz":-120,"elapsed":5,"user":{"displayName":"armen hakobyan","userId":"02066644010986801761"}},"outputId":"72aa5861-a2f5-460a-aafc-e6e0d00721b3"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\n# --- BLOQUE DE CÓDIGO DE GRAFICACIÓN (ADAPTADO PARA KNN) ---\\n\\n# Importar KNN y Scaler para re-entrenar\\nfrom sklearn.neighbors import KNeighborsRegressor\\nfrom sklearn.preprocessing import StandardScaler\\nimport matplotlib.dates as mdates\\n\\n\\n# --- Selección de Grupos y Generación de Gráficos ---\\ngrupos_a_graficar = [\\n    (\\'conventional\\', \\'BuffaloRochester\\'),\\n    (\\'organic\\', \\'NewYork\\'),\\n    (\\'conventional\\', \\'SanFrancisco\\'),\\n    # (\\'conventional\\', \\'Nashville\\'),\\n    # (\\'conventional\\', \\'West\\')\\n]\\n\\n# Verificar si las variables necesarias existen\\nif (\\'indices_imputados_global\\' not in locals() or \\'df2\\' not in locals()\\n    or \\'min_train_samples\\' not in locals() or \\'n_neighbors_knn\\' not in locals()):\\n     print(\"Error: Variables de imputación no encontradas (df2, indices_imputados_global, etc.).\")\\n     print(\"Asegúrate de ejecutar el bloque de imputación KNN primero.\")\\n     exit()\\nelse:\\n    print(f\"\\n--- Generando gráficos para {len(grupos_a_graficar)} grupos seleccionados usando KNN (datos de df2) ---\")\\n\\n    # Re-asegurar columnas necesarias para graficar\\n    if not all(col in df2.columns for col in [\\'type\\', \\'region\\', \\'Date\\', \\'Large Bags\\', \\'Fecha_Ordinal\\', \\'Mes\\', \\'SemanaDelAno\\']):\\n         print(\"Error: Faltan columnas necesarias para graficar en df2.\"); exit()\\n\\n    for tipo_plot, region_plot in grupos_a_graficar:\\n\\n        print(f\"\\nGenerando gráfico para: type=\\'{tipo_plot}\\', region=\\'{region_plot}\\'\")\\n\\n        df_grupo = df2[(df2[\\'type\\'] == tipo_plot) & (df2[\\'region\\'] == region_plot)].sort_index().copy()\\n\\n        if df_grupo.empty: print(\"   -> No hay datos para este grupo.\"); continue\\n\\n        indices_imputados_grupo = df_grupo.index.intersection(indices_imputados_global)\\n        mask_imputed = df_grupo.index.isin(indices_imputados_grupo)\\n        mask_original_nonzero = (df_grupo[\\'Large Bags\\'] > 0)\\n        mask_original_zero_not_imputed = (~mask_original_nonzero) & (~mask_imputed)\\n\\n        # --- Re-entrenar el modelo KNN y predecir para todo el grupo (para la línea) ---\\n        train_data_plot = df_grupo[mask_original_nonzero]\\n\\n        knn_reg_plot = None\\n        pred_line = None\\n        pred_dates = None\\n        can_plot_line = False\\n\\n        # Comprobar si hay suficientes datos originales (>0) y si son suficientes para los vecinos k\\n        if len(train_data_plot) >= min_train_samples and len(train_data_plot) >= n_neighbors_knn:\\n            print(f\"   -> Re-entrenando modelo KNN con {len(train_data_plot)} puntos originales (>0).\")\\n            try:\\n                features = [\\'Fecha_Ordinal\\', \\'Mes\\', \\'SemanaDelAno\\']\\n                X_train_plot = train_data_plot[features]\\n                y_train_plot = train_data_plot[\\'Large Bags\\']\\n                # Preparar features para TODOS los puntos del grupo para obtener la línea de predicción\\n                X_group_plot = df_grupo[features]\\n\\n                # Escalar\\n                scaler_plot = StandardScaler()\\n                X_train_plot_scaled = scaler_plot.fit_transform(X_train_plot)\\n                X_group_plot_scaled = scaler_plot.transform(X_group_plot) # Usar mismo scaler\\n\\n                # Entrenar\\n                knn_reg_plot = KNeighborsRegressor(n_neighbors=n_neighbors_knn, weights=\\'distance\\')\\n                knn_reg_plot.fit(X_train_plot_scaled, y_train_plot)\\n\\n                # Predecir para todos los puntos del grupo\\n                pred_line_raw = knn_reg_plot.predict(X_group_plot_scaled)\\n                pred_line = np.maximum(0, pred_line_raw) # Cap negativos\\n                pred_dates = df_grupo.index # Fechas correspondientes\\n                can_plot_line = True\\n\\n            except Exception as e:\\n                print(f\"   -> Error al re-entrenar o predecir para la línea KNN: {e}\")\\n        else:\\n            print(f\"   -> No se puede trazar la línea KNN (datos originales > 0 son {len(train_data_plot)}, se necesitan {max(min_train_samples, n_neighbors_knn)}).\")\\n\\n        # --- Crear el Gráfico ---\\n        plt.figure(figsize=(15, 7))\\n\\n        plt.scatter(df_grupo.loc[mask_original_nonzero].index, df_grupo.loc[mask_original_nonzero, \\'Large Bags\\'],\\n                    label=\\'Original (>0)\\', alpha=0.6, color=\\'blue\\', s=30)\\n        if not df_grupo.loc[mask_imputed].empty:\\n             plt.scatter(df_grupo.loc[mask_imputed].index, df_grupo.loc[mask_imputed, \\'Large Bags\\'],\\n                         label=\\'Imputado (Originalmente 0)\\', alpha=0.9, color=\\'orange\\', marker=\\'X\\', s=60)\\n        if not df_grupo.loc[mask_original_zero_not_imputed].empty:\\n              plt.scatter(df_grupo.loc[mask_original_zero_not_imputed].index, df_grupo.loc[mask_original_zero_not_imputed, \\'Large Bags\\'],\\n                         label=\\'Originalmente 0 (No Imputado)\\', alpha=0.7, color=\\'red\\', marker=\\'o\\', s=40)\\n\\n        # Graficar la línea de predicción KNN si se pudo calcular\\n        if can_plot_line and pred_line is not None and pred_dates is not None:\\n             # Crear un df temporal para ordenar por fecha antes de graficar linea\\n             line_df = pd.DataFrame({\\'Date\\': pred_dates, \\'Prediction\\': pred_line}).sort_values(by=\\'Date\\')\\n             plt.plot(line_df[\\'Date\\'].dt.to_pydatetime(), line_df[\\'Prediction\\'],\\n                      color=\\'green\\', linestyle=\\'--\\', linewidth=2, label=f\\'Predicción KNN (k={n_neighbors_knn})\\')\\n\\n        plt.title(f\\'Large Bags vs Tiempo (Imputado con KNN) - {tipo_plot.capitalize()} / {region_plot}\\')\\n        plt.xlabel(\\'Fecha\\')\\n        plt.ylabel(\\'Large Bags\\')\\n        plt.legend()\\n        plt.grid(True, axis=\\'y\\', linestyle=\\':\\')\\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\\'%Y-%m-%d\\'))\\n        plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator(minticks=5, maxticks=10))\\n        plt.gcf().autofmt_xdate()\\n        plt.tight_layout()\\n        plt.show()\\n    '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]}]}